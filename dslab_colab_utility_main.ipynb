{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+OEFQ1eQ9tUvE76p4JdOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemvardar/pragmatic_google_colab/blob/main/dslab_colab_utility_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h6YobZHn4CyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45aa0712-65da-4c75-bdcd-4d1b2f4113cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pymongo\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import random\n",
        "import folium\n",
        "from pymongo import MongoClient, UpdateOne\n",
        "import urllib.parse\n",
        "from datetime import datetime\n",
        "from google.oauth2 import service_account\n",
        "import mimetypes\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import httplib2\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from google.colab import sheets\n",
        "from IPython.display import HTML, display\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def read_df_from_sheet_gspread(sheet_url, worksheet_name=None):\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    # Extract the sheet ID from the URL\n",
        "    sheet_id = sheet_url.split('/d/')[1].split('/')[0]\n",
        "\n",
        "    sheet = gc.open_by_key(sheet_id)\n",
        "    if worksheet_name:\n",
        "        worksheet = sheet.worksheet(worksheet_name)\n",
        "        values = worksheet.get_all_values()\n",
        "        df = pd.DataFrame(values[1:], columns=values[0])  # This assumes the first row is the header\n",
        "        return df\n",
        "\n",
        "    if worksheet_name is None and len(sheet.worksheets())==1:\n",
        "        worksheet = sheet.worksheets()[0]\n",
        "        values = worksheet.get_all_values()\n",
        "        df = pd.DataFrame(values[1:], columns=values[0])  # This assumes the first row is the header\n",
        "        return df\n",
        "\n",
        "    df_dict = {}\n",
        "    for worksheet in sheet.worksheets():\n",
        "    # Use the first sheet by default, or specify the name of the sheet you want to access\n",
        "\n",
        "        # Get all values from the sheet\n",
        "        values = worksheet.get_all_values()\n",
        "\n",
        "        # Convert to a pandas DataFrame\n",
        "        df = pd.DataFrame(values[1:], columns=values[0])  # This assumes the first row is the header\n",
        "        df_dict[worksheet.title] = df\n",
        "    return df_dict\n",
        "\n",
        "\n",
        "def post_to_rest_api(payload, url):\n",
        "    headers = {'Content-type': 'application/json', 'Accept': 'application/json'}\n",
        "    r = requests.post(url,\n",
        "                      json.dumps(payload),\n",
        "                      headers=headers)\n",
        "    return r\n",
        "\n",
        "def get_df_from_sheet(key, sheet_name):\n",
        "    url = 'http://decisionsciencelab.com/api/v1.0/get_sheet_json'\n",
        "    payload = {'key':key,\n",
        "               'sheet_name':sheet_name}\n",
        "    r = post_to_rest_api(payload, url)\n",
        "    return pd.DataFrame(r.json())\n",
        "\n",
        "\n",
        "def get_mongodb_url():\n",
        "    userid = secrets['mongodb_user']\n",
        "    password = urllib.parse.quote_plus(secrets['mongodb_password'])\n",
        "    mongodb_uri = \"mongodb+srv://\" + userid + \":\" + password + \"@location-selection.vfmji.gcp.mongodb.net/location_selection?retryWrites=true&w=majority\"\n",
        "    return mongodb_uri\n",
        "\n",
        "\n",
        "def get_document_list_from_mongodb(db_name, collection_name):\n",
        "    client = MongoClient(get_mongodb_url(), retryWrites=False)\n",
        "    database = client[db_name]\n",
        "    list_records = [doc for doc in database[collection_name].find()]\n",
        "    return list_records\n",
        "\n",
        "\n",
        "def get_df_from_mongodb(db_name, collection_name):\n",
        "    list_records = get_document_list_from_mongodb(db_name, collection_name)\n",
        "    df = pd.DataFrame(list_records)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_collection(db_name, collection_name):\n",
        "    client = MongoClient(get_mongodb_url(), retryWrites=False)\n",
        "    database = client[db_name]\n",
        "    return database[collection_name]\n",
        "\n",
        "\n",
        "def insert(db_name, collection_name, json_doc):\n",
        "    collection = get_collection(db_name, collection_name)\n",
        "    collection.insert_one(json_doc)\n",
        "\n",
        "def insert_many(db_name, collection_name, json_docs):\n",
        "    \"\"\"Inserts multiple JSON documents into a MongoDB collection.\n",
        "\n",
        "    Args:\n",
        "        db_name: The name of the database.\n",
        "        collection_name: The name of the collection.\n",
        "        json_docs: A list of JSON documents to insert.\n",
        "    \"\"\"\n",
        "    collection = get_collection(db_name, collection_name)\n",
        "    collection.insert_many(json_docs)\n",
        "\n",
        "\n",
        "def upsert(db_name, collection_name, query, doc_to_upsert):\n",
        "    collection = get_collection(db_name, collection_name)\n",
        "    # collection.update(query, doc_to_upsert, upsert=True, safe=True)\n",
        "    collection.update_one(query, {'$set': doc_to_upsert}, upsert=True)\n",
        "\n",
        "def upsert_many(db_name, collection_name, json_docs, filter_key='_id'):\n",
        "    \"\"\"Upserts multiple JSON documents into a MongoDB collection.\n",
        "\n",
        "    Args:\n",
        "        db_name: The name of the database.\n",
        "        collection_name: The name of the collection.\n",
        "        json_docs: A list of JSON documents to upsert.\n",
        "        filter_key: The key to use for filtering existing documents.\n",
        "                    Defaults to '_id'.\n",
        "    \"\"\"\n",
        "    collection = get_collection(db_name, collection_name)\n",
        "    requests = []\n",
        "    for doc in json_docs:\n",
        "        filter = {filter_key: doc[filter_key]} if filter_key in doc else doc\n",
        "        update = {'$set': doc}\n",
        "        request = UpdateOne(filter, update, upsert=True)\n",
        "        requests.append(request)\n",
        "\n",
        "    if requests:\n",
        "        result = collection.bulk_write(requests)\n",
        "        print(f\"Upserted {result.upserted_count} documents, \"\n",
        "              f\"modified {result.modified_count} documents.\")\n",
        "\n",
        "\n",
        "def now():\n",
        "    return datetime.now()\n",
        "\n",
        "\n",
        "def get_gcp_bucket_credentials():\n",
        "    creds = {\n",
        "    \"type\": \"service_account\",\n",
        "    \"project_id\": \"cem-k8-test\",\n",
        "    \"private_key_id\": \"\",\n",
        "    \"private_key\": \"\",\n",
        "    \"client_email\": \"dslab-gcp-bucket@cem-k8-test.iam.gserviceaccount.com\",\n",
        "    \"client_id\": \"101834349465593903398\",\n",
        "    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "    \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/dslab-gcp-bucket%40cem-k8-test.iam.gserviceaccount.com\"\n",
        "    }\n",
        "    creds[\"private_key_id\"]=secrets['gcp_private_key_id']\n",
        "    creds[\"private_key\"]=secrets['gcp_private_key'].replace('\\\\n', '\\n')\n",
        "    gcp_bucket_credentials = service_account.Credentials.from_service_account_info(creds)\n",
        "    return gcp_bucket_credentials\n",
        "\n",
        "\n",
        "def upload_file_to_gcp_generic_mime_type(file_name, sub_folder_path, delete_file_from_local = False):\n",
        "    bucket_name = 'decision-science-lab-bucket'\n",
        "    project_id = 'cem-k8-test'\n",
        "    client = storage.Client(project=project_id, credentials=get_gcp_bucket_credentials())\n",
        "\n",
        "    mime_type, _ = mimetypes.guess_type(file_name)\n",
        "    if mime_type is None:\n",
        "        mime_type = 'application/octet-stream'  # Default/fallback MIME type\n",
        "    upload_file_name = file_name.replace(' ', '_')\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(f\"{sub_folder_path}/{upload_file_name}\")\n",
        "    blob.upload_from_filename(file_name, content_type=mime_type)\n",
        "\n",
        "    # Delete local file\n",
        "    if delete_file_from_local and os.path.exists(file_name):\n",
        "        os.remove(file_name)\n",
        "        print(f\"{file_name} successfully uploaded to GCP and deleted from local\")\n",
        "\n",
        "    uploaded_file_gcp_link = f'https://storage.googleapis.com/decision-science-lab-bucket/' \\\n",
        "                     f'{sub_folder_path}/{upload_file_name}'\n",
        "    print(uploaded_file_gcp_link)\n",
        "    return uploaded_file_gcp_link\n",
        "\n",
        "\n",
        "def get_all_urls_in_gcp_sub_folder_path(sub_folder_path):\n",
        "    bucket_name = 'decision-science-lab-bucket'\n",
        "    project_id = 'cem-k8-test'\n",
        "    client = storage.Client(project=project_id, credentials=get_gcp_bucket_credentials())\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blobs = client.list_blobs(bucket_name, prefix=sub_folder_path + '/')\n",
        "    url_prefix = 'https://storage.googleapis.com/decision-science-lab-bucket/'\n",
        "    url_list = []\n",
        "    for blob in blobs:\n",
        "        url_list.append(url_prefix+blob.name)\n",
        "    return url_list\n",
        "\n",
        "\n",
        "def get_secrets():\n",
        "    sheet_url = 'https://docs.google.com/spreadsheets/d/1mLwdiSnTi0KoB8Zg6kMclTXXm3f_JavMX-5lAUp-Ry0/edit#gid=0'\n",
        "    sheet_name = 'dev'\n",
        "    df_keys = read_df_from_sheet_gspread(sheet_url, worksheet_name=sheet_name)\n",
        "    key_dict = dict(zip(df_keys['key'], df_keys['value']))\n",
        "    return key_dict\n",
        "\n",
        "\n",
        "secrets = get_secrets()"
      ],
      "metadata": {
        "id": "9gSvmGJK4PPb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def upload_gdrive_file_to_gcp_generic_mime_type(file_path, gcp_path):\n",
        "    video_filename = file_path.split('/')[-1]\n",
        "    destination_path = f'/content/{video_filename}' # Copy to current Colab directory\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        shutil.copy2(file_path, destination_path) # copy2 preserves metadata\n",
        "        print(f\"File '{file_path}' copied successfully to '{destination_path}'\")\n",
        "    else:\n",
        "        print(f\"Error: Source file '{file_path}' not found.\")\n",
        "    video_url = upload_file_to_gcp_generic_mime_type(video_filename, gcp_path, delete_file_from_local = True)\n",
        "    return video_url\n",
        "\n",
        "\n",
        "# sub_folder_path = 'liplips/roma_silvers_products'\n",
        "# urls = get_all_urls_in_gcp_sub_folder_path(sub_folder_path)\n",
        "# urls[:5]\n",
        "# len(urls)"
      ],
      "metadata": {
        "id": "HmubhYeW5ThV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_name_for_export_with_date_time(file_name_header, file_extenstion):\n",
        "    formatted_datetime = now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
        "    file_name = f\"{file_name_header}_{formatted_datetime}.{file_extenstion}\"\n",
        "    file_name = file_name.replace(' ', '_')\n",
        "    return file_name"
      ],
      "metadata": {
        "id": "RMMnAdMy8Rfh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_stamp_string():\n",
        "    return now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
        "\n",
        "# get_time_stamp_string()"
      ],
      "metadata": {
        "id": "C5zFM_6z8uSo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import json_normalize\n",
        "\n",
        "def sum_last_3_views(performance_metrics, field):\n",
        "    \"\"\"Sums the views from the last 3 metric records.\n",
        "\n",
        "    Args:\n",
        "        performance_metrics: A list of performance metrics.\n",
        "\n",
        "    Returns:\n",
        "        The sum of views from the last 3 records, or 0 if there are fewer than 3 records.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        last_3_records = performance_metrics[-3:]\n",
        "        total_views = sum([record.get(field, 0) for record in last_3_records])\n",
        "        return total_views\n",
        "    except (TypeError, IndexError):\n",
        "        return 0  # Handle cases with missing data or fewer than 3 records\n",
        "\n",
        "def get_start_end_dates(performance_metrics):\n",
        "    \"\"\"Gets the start date of the -3 record and end date of the last record.\n",
        "\n",
        "    Args:\n",
        "        performance_metrics: A list of performance metrics.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the start and end dates, or (None, None) if there are issues.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        length = len(performance_metrics)\n",
        "        start_date = performance_metrics[-min(3, length)]['start_date']  # Assuming 'start_date' is the key\n",
        "        end_date = performance_metrics[-1]['end_date']   # Assuming 'end_date' is the key\n",
        "        return pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
        "    except (TypeError, IndexError, KeyError):\n",
        "        return None, None  # Handle potential errors\n",
        "\n",
        "def get_tag_list(df_row):\n",
        "    tag_list = []\n",
        "    for i in range(1,14):\n",
        "        if pd.notnull(df_row[f'tag_{i}']) and len(df_row[f'tag_{i}'])>0:\n",
        "            tag_list.append(df_row[f'tag_{i}'])\n",
        "    # print(tag_list)\n",
        "    return tag_list\n",
        "\n",
        "def get_current_etsy_data_df():\n",
        "    etsy_all_data_df = get_df_from_mongodb('location_selection', 'etsy_listings')\n",
        "    etsy_all_data_df['performance_metrics_last_read'] = etsy_all_data_df['performance_metrics'].apply(lambda x: x[-1] if type(x)==list else None)\n",
        "    columns = ['views', 'favourites', 'order', 'revenue']\n",
        "    for column in columns:\n",
        "        etsy_all_data_df[f'total_{column}_last_3'] = etsy_all_data_df['performance_metrics'].apply(sum_last_3_views, field=column)\n",
        "    etsy_all_data_df[['start_date', 'end_date']] = etsy_all_data_df['performance_metrics'].apply(lambda x: pd.Series(get_start_end_dates(x)))\n",
        "    etsy_all_data_df['start_date'] = pd.to_datetime(etsy_all_data_df['start_date'])\n",
        "    etsy_all_data_df['end_date'] = pd.to_datetime(etsy_all_data_df['end_date'])\n",
        "    etsy_all_data_df['metric_days'] = (etsy_all_data_df['end_date'] - etsy_all_data_df['start_date']).dt.days\n",
        "    etsy_all_data_df['tag_list'] = etsy_all_data_df.apply(get_tag_list, axis=1)\n",
        "    return etsy_all_data_df\n",
        "\n",
        "# df = get_current_etsy_data_df()\n",
        "# df[['listing_id', 'total_views_last_3',\n",
        "#                   'total_favourites_last_3','total_revenue_last_3',\n",
        "#                   'total_order_last_3',\n",
        "#                   'start_date', 'end_date', 'metric_days' ]]"
      ],
      "metadata": {
        "id": "09r2DE8sDndq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "  \"\"\"Gets the duration of a video file in seconds.\n",
        "\n",
        "  Args:\n",
        "    video_path: The path to the video file.\n",
        "\n",
        "  Returns:\n",
        "    The duration of the video in seconds, or None if the file is not found.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    clip = VideoFileClip(video_path)\n",
        "    duration = clip.duration\n",
        "    clip.close()  # Close the clip to release resources\n",
        "    return duration\n",
        "  except Exception as e:\n",
        "    print(f\"Error getting video duration for {video_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "# get_video_duration(\"/content/Fenomenlik_aslanın_ağzında.mp4\")"
      ],
      "metadata": {
        "id": "66gR5maSGzd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd6ba75-232d-4dae-fef8-7fb53375deb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.17"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_video(video_path, start_time, end_time, output_path):\n",
        "  \"\"\"Cuts a video file from start_time to end_time and saves the output.\n",
        "\n",
        "  Args:\n",
        "    video_path: The path to the input video file.\n",
        "    start_time: The start time in seconds.\n",
        "    end_time: The end time in seconds.\n",
        "    output_path: The path to save the cut video.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    clip = VideoFileClip(video_path)\n",
        "    subclip = clip.subclip(start_time, end_time)\n",
        "    subclip.write_videofile(output_path)\n",
        "    clip.close()  # Close the clip to release resources\n",
        "    print(f\"Video successfully cut and saved to {output_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error cutting video {video_path}: {e}\")\n",
        "\n",
        "# cut_video(\"Fenomenlik_aslanın_ağzında.mp4\", 2, 5, \"Fenomenlik_aslanın_ağzında_kisa.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U54iFjARbmux",
        "outputId": "e6d3364d-8699-4a62-e913-4701250abe40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video Fenomenlik_aslanın_ağzında_kisa.mp4.\n",
            "MoviePy - Writing audio in Fenomenlik_aslanın_ağzında_kisaTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video Fenomenlik_aslanın_ağzında_kisa.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready Fenomenlik_aslanın_ağzında_kisa.mp4\n",
            "Video successfully cut and saved to Fenomenlik_aslanın_ağzında_kisa.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file_from_url(url, filename=None):\n",
        "    \"\"\"Downloads a file from a URL.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the file to download.\n",
        "        filename: The local filename to save the downloaded file as.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        if filename==None:\n",
        "            filename = os.path.basename(url)\n",
        "        with open(filename, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(f\"File downloaded successfully as {filename}\")\n",
        "        return filename\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "\n",
        "# url = 'https://storage.googleapis.com/decision-science-lab-bucket/derin_seinfeld/tvittvitanadolu/bolum_edits/domates_kamyonu/shorts/Ak%C5%9Fam_yeme%C4%9Finde_domat_var..mp4'\n",
        "# download_file_from_url(url, '/content/sample_data/testing.mp4')"
      ],
      "metadata": {
        "id": "rQ3ep06xcBWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d282bb3f-4fd6-4f24-f808-8f71a65022cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully as /content/sample_data/testing.mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data/testing.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_audio(video_file_path, gcp_folder_path):\n",
        "    file_name = os.path.basename(video_file_path)\n",
        "    if '.mp4' in file_name:\n",
        "        video_clip = VideoFileClip(video_file_path)\n",
        "        audio_clip = video_clip.audio\n",
        "        audio_file_name = video_file_path.replace('.mp4', '.mp3')\n",
        "        audio_clip.write_audiofile(audio_file_name, codec='mp3')\n",
        "\n",
        "    # sub_folder_path = f'derin_seinfeld/tvittvitanadolu/bolum_edits/{bolum_folder_name}'\n",
        "    file_name = os.path.basename(audio_file_name).replace('.mp4', '.mp3')\n",
        "    if audio_file_name!= file_name:\n",
        "        shutil.copy(audio_file_name, file_name)\n",
        "    saved_audio_test_url = upload_file_to_gcp_generic_mime_type(file_name, gcp_folder_path, delete_file_from_local = False)\n",
        "    return saved_audio_test_url\n",
        "\n",
        "def save_audio_from_url(url, gcp_folder_path):\n",
        "    file_name = download_file_from_url(url)\n",
        "    return save_audio(file_name, gcp_folder_path)\n",
        "\n",
        "# gcp_folder_path = f'derin_seinfeld/tvittvitanadolu/test'\n",
        "# save_audio('/content/sample_data/testing.mp4', gcp_folder_path)\n",
        "# url = 'https://storage.googleapis.com/decision-science-lab-bucket/derin_seinfeld/tvittvitanadolu/bolum_edits/domates_kamyonu/shorts/Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp4'\n",
        "# save_audio_from_url(url, gcp_folder_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "XBMC8VINozR5",
        "outputId": "a59ec3b1-01b2-4764-9bbe-5686164c7fe2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully as Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp4\n",
            "MoviePy - Writing audio in Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "https://storage.googleapis.com/decision-science-lab-bucket/derin_seinfeld/tvittvitanadolu/test/Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://storage.googleapis.com/decision-science-lab-bucket/derin_seinfeld/tvittvitanadolu/test/Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files_and_folders(folder_path):\n",
        "  \"\"\"Lists all files and folders in a given directory.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the directory.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing two lists: one for files and one for folders.\n",
        "  \"\"\"\n",
        "  files = []\n",
        "  folders = []\n",
        "  for item in os.listdir(folder_path):\n",
        "    item_path = os.path.join(folder_path, item)\n",
        "    if os.path.isfile(item_path):\n",
        "      files.append(item)\n",
        "    elif os.path.isdir(item_path):\n",
        "      folders.append(item)\n",
        "  return files, folders\n",
        "\n",
        "# list_files_and_folders('/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6nWYZYgrmjF",
        "outputId": "73d219b7-715c-42d6-81dd-d47ee0284c33"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp3',\n",
              "  'Fenomenlik_aslanın_ağzında.mp4',\n",
              "  'Ak%C5%9Fam_yeme%C4%9Finde_domat_var..mp4',\n",
              "  'Fenomenlik_aslanın_ağzında_kisa.mp4',\n",
              "  'testing.mp3',\n",
              "  'Bir_hedef_u%C4%9Fruna_yek_v%C3%BCcut.mp4'],\n",
              " ['.config', '.ipynb_checkpoints', 'sample_data'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import sheets\n",
        "def get_transcript_from_audio(audio_url):\n",
        "    audio_filename = audio_url.split('/')[-1]\n",
        "    api_url = 'https://www.decisionsciencelab.com/load_utterances'\n",
        "    data = {\n",
        "        'audio_url': audio_url,\n",
        "        'podcast_name': 'tvittvitanadolu',  # Replace YOUR_PODCAST_NAME with the actual podcast name.\n",
        "        'episode_title': f'manual_episode {audio_filename}',  # Replace YOUR_EPISODE_TITLE with the actual episode title.\n",
        "        'current_speaker_mapping': {}  # Populate with your current speaker mapping.\n",
        "    }\n",
        "    response = requests.post(api_url, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print('Utterances loaded successfully!')\n",
        "        response_data = response.json()  # Store the response data in a variable\n",
        "        utterances = response_data['utterances']\n",
        "        transcript = response_data['transcript']\n",
        "        speaker_mapping = response_data['speaker_mapping']\n",
        "        topics = response_data['topics']\n",
        "        audio_gcp_link = response_data['audio_gcp_link']\n",
        "\n",
        "        # Now you can use the variables 'utterances', 'transcript', etc.\n",
        "        # For example, to print the utterances:\n",
        "        print(utterances)\n",
        "    else:\n",
        "        print(f'Error loading utterances: {response.status_code}')\n",
        "\n",
        "    # import pandas as pd\n",
        "    utterance_rows = []\n",
        "    for utterance in utterances.values():\n",
        "        utterance_rows.append([utterance['start'], utterance['end'], utterance['transcript']])\n",
        "        # print(utterance['transcript'])\n",
        "    df = pd.DataFrame(utterance_rows, columns=['start', 'end', 'transcript'])\n",
        "    df = df.sort_values(by='start')\n",
        "    # from google.colab import sheets\n",
        "    df_sheet = sheets.InteractiveSheet(df= df, display=False)\n",
        "    return response_data, df_sheet\n",
        "\n",
        "# audio_url = 'https://storage.googleapis.com/decision-science-lab-bucket/derin_seinfeld/tvittvitanadolu/test/testing.mp3'\n",
        "# response_data, df_sheet = get_transcript_from_audio(audio_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g8j-yRzsCWy",
        "outputId": "3fb9b50f-6ccb-4133-8261-0534351a72c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utterances loaded successfully!\n",
            "{'0': {'end': 2.82, 'id': '0', 'speaker': 0, 'start': 0.08, 'transcript': 'Akşam yemeği yiyemeyecek kadar yedim, diyor.'}, '1': {'end': 10.179999, 'id': '1', 'speaker': 0, 'start': 5.2799997, 'transcript': 'Bedava da olsa bir insan akşam yemeği yiyemeyecek kadar domates yiyebilir mi?'}, '2': {'end': 14.171062, 'id': '2', 'speaker': 0, 'start': 10.24, 'transcript': 'Yani İmkansız bir şey Yani imkansız.'}, '3': {'end': 20.506124, 'id': '3', 'speaker': 0, 'start': 14.231062, 'transcript': 'Böyle bir senaryoyu ancak gerçekten bizim ana akım medyamız icat edebilir'}}\n",
            "https://docs.google.com/spreadsheets/d/1Ifp4Tlw6qxMVGrTyopx7MhUIV93bMEVmtLSYWafrg7Q/edit#gid=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VY05IRaFssFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}